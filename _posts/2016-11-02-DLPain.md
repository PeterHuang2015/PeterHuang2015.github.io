---
layout: post
comments: false
title:  "深度学习-工具之痛"
excerpt: "烫烫烫烫烫烫烫"
date:   2016-11-02 11:17:00
---

## 前言

部分程序员掌握修电脑装系统的技能通常是由于手贱。。。

编者笔记本和 Ubuntu 启动盘死磕上瘾一次启动24小时都进不去界面之后只能转战老旧的台式机了。。。顺手想装装系统捞几个工具库来用一搞就是一天～

公号最近实在没别的可说的，就赶时髦来聊聊深度学习，主要吐槽工具包。

当初像我这么肤浅的人竟误入了深度学习的坑，主要是想着这样的东西可以反过来帮助我们理解人脑为祖国的教育事业做贡献；naive，这种十八弯一样的思路把八杆子打不着的东西凑一起也是闹。

有关神(shen)经(du)网(xue)络(xi)的英文资料一抓一大把了，可不吐不快，不写出来实在不知道自己知道点啥。

程序运行的过程如同一场演出，观众与导演的角色截然不同；用户是前排看戏的，各种数据结构工具库加上杂七杂八的硬件是场上演出的，写程序的家伙们则是后台忙里忙外的，稍不留神就一个趔趄摔倒在地被一堆电缆缠的动弹不得，被 bug 咬地满头包。。。这种时候找个靠谱的工具包十分必要，如同普通青年小时候玩四驱车得把原件买来才行，空手造一个顶多捏个纸的。

关于深度学习到底是个啥推荐各位阅读---__李宏毅：一天搞懂深度学习__，二百多页的 PPT 能让人看到这项技术的大概轮廓；由于坑多，相关主题在部分科研学者圈子里还会继续火下去。作为打工仔，编者最关心的是工具包的问题。

别家的网络和工具拿来用如同套公式一样往 paper 里塞，胃容量小的我实在受不了这样填鸭，在去年的暑假尝试着用 C 写一套自己的工具自用，未果。。。一周后卡在 BP 部分上丢在 github 上作未完待续状，这种时候只好抱抱大腿先。

一条咸鱼在各种工具包中翻滚过，到头来对它们的了解大概只有这么浅，烛火微光，防止朋友踩坑。。。以下工具包均可在网络上开放获取，特别鸣谢著名同性交友社区 Github 的代码托管支持。

+ Pybrain -Jürgen Schmidhuber 的学生在距今十年前就开始的项目，速度不(hen)快(man)，但里面的实现简捷漂亮，可以初学使用，并在小规模数据下进行网络验证与快速实验。
+ FANN - 当前年龄在十岁以上诞生自丹麦的神经网络工具包，使用 C 语言实现，可以方便移植，网络上可搜索到编译并将其嵌入到 IOS APP 的博文。
+ Matconvnet - vlfeat 工程组为广大 Matlab 死忠准备的 CNN 工具包，方便简单见效快。
+ Kaldi - 语音相关领域研究者青睐的专门工具包
+ CNTK - 微软深度学习框架，最近改了名字。
+ Theano - 蒙特利尔出产的使用广泛而历史也比较久的工具
+ Torch - 产自纽约大学，使用轻量化的 Lua 力求最大的灵活性，贴着 Facebook 的标签
+ Caffe - 某乎网红论文搞定剩下俩月没事干写出来的工具包，对于大数据量需要使用 GPU 加速训练深层网络的情况尤其合适，2014 年来广受欢迎
+ cuRRent - 简单易用语音相关神经网络工具包
+ Tensorflow - 黄金工程团队谷歌开源的内部机器学习系统
+ Keras - 套在 Theano 和 Tensorflow 外层上的很好用的壳
+ mxnet - 神秘组织 dmlc 产物，支持语言非常全
+ darknet - Little Pony 爱好者 Joseph 凭着本科时撸 ACM 的功力写的工具包，基本没什么工具依赖，相对那些大号工具包代码量小跑的很快，用起来只要一个可执行文件就好。
+ DIGITS - 核弹厂给 Caffe 加的一层壳
+ opencv - 今年的 Google Summer of Code 活动学生们决定为开发中的 opencv 版本继续完善神经网络相关的部分，之前的版本只有感知机可用

讲真，被滥用的深度学习方法看起来简直是核弹厂老黄卖显卡、公司围攻傲娇研究团体、小年轻在老学究圈子里搏出位的必备出装。只想说，显卡是 AMD 或者 N 卡计算能力低于 2.0 的，机器固件和 Ubuntu 有仇的，只要是工具包都喜欢尝尝鲜用最新版的，入坑都要三思而后行。

## XOR in Pybrain
开始接触一个工具总要有个 Hello World 一样的东西，当年感知机被指出的致命缺点就是无法学到 xor。

要逼近亦或函数，在神经网络里加上隐层即可。

豪杰解霸的作者当年招进去的一批员工发展最好的是个入职只会 C 语言的，花里胡哨的技术太多，太该紧跟潮流反而学不到真东西，或者说练不到内功。。用牺牲速度换取易用性的 Pybrain，我们可以快速构建一个简单网络并进行实验，参照官方文档对应代码如下。

```python
from pybrain.tools.shortcuts import buildNetwork
from pybrain.structure import SoftmaxLayer, TanhLayer
from pybrain.datasets import SupervisedDataSet
from pybrain.supervised.trainers import BackpropTrainer

net = buildNetwork(2, 3, 1, hiddenclass=TanhLayer, outclass=SoftmaxLayer)

ds = SupervisedDataSet(2,1)
ds.addSample((0, 0), (0))
ds.addSample((0, 1), (1))
ds.addSample((0, 1), (1))
ds.addSample((1, 1), (0))

trainer = BackpropTrainer(net, ds)
trainer.trainUntilConvergence()

net.activiate([1, 0])
```

要具体查看网络结构以及数据内容，可以使用库自带的接口

```python
net["in"]
net["hidden0"]
net["out"]

net.activate([2,1])

ds["input"]
ds["target"]

for input, target in ds:
    print input, target
```

这里我们讲 XOR 作为一个简单而具有代表性的思维模型，用神经网络进行拟合，把离散的问题归入连续函数模型当中，利用给出样本进行逼近，试了试这条路是不是走的通。微信发代码技能 get!下节，我们从一个填空题的角度来看这些代码处理的对象是个什么鬼。。

---
category: 'Toolkits'
title: 'Caffe Guide'
type: 'Toolkit'
path: '/toolkits/:id'
layout: null
---

Caffe was purposed and implemented in 2014 as the follow-up work done by [Yangqing Jia](http://daggerfs.com/index_old.html) after published their ICML [paper](https://arxiv.org/abs/1310.1531), the prototype was called [DeCAF](https://github.com/UCBAIR/decaf-release). The framework was introduced to fast-prototyping training and testing of convolutional neural networks.

Caffe was not the first deep learning framework, nor the last one. It was successful due to the easy-to-reuse feature, support for command-line, python and MATLAB interface and rich model zoo. It heavily depends on a bunch of libraries which makes the compiling procedure painful and troublesome. Caffe was gradually replaced by other newly appeared frameworks but it's concept in implementation and even partial of code has been inherited by new generations.

The logic behind Caffe is clear, the data are saved in a 4-dimension array(blob), flow between layers, both forward and backward, weight update controlled by optimizers. The whole model defined by protobuf specifications and declarations which looks similar to SUN RPC. Accelerated by CUDA, tested using GTest, en-powered by libraries like boost. But due to the various sources of input data, lots of Caffe code dedicated to data loading and pre-processing which may be confusing if you are not familiar with distributed file systems and other related topics. Customized Caffe and layers are also available in different sites(mainly on github) for specific purpose, Nvidia also provided a customized [Caffe](https://github.com/NVIDIA/caffe) which has been optimized with support for new tech like TensorRT.

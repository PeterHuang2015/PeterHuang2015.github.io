<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Peter Huang&#39;s Blog</title>
    <description></description>
    <link>http://talkwithme.cn//</link>
    <atom:link href="http://talkwithme.cn//feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Wed, 30 Nov 2016 12:21:05 +0000</pubDate>
    <lastBuildDate>Wed, 30 Nov 2016 12:21:05 +0000</lastBuildDate>
    <generator>Jekyll v3.1.6</generator>
    
      <item>
        <title>深度学习-真的能一天弄懂深度学习？</title>
        <description>&lt;h2 id=&quot;section&quot;&gt;前言&lt;/h2&gt;

&lt;p&gt;上期推荐过李宏毅的《一天搞懂深度学习》教程，其实人家题目是 Deep Learning Tutorial，深度学习这东西像围棋，易于入门难于精深，花一天时间给您用 286 页 PPT&lt;del&gt;学会&lt;/del&gt;的深度学习，大概就是学了个80%，像下图这个样子：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/huama.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;为了跳出焦虑症-松鼠症-懒癌的死循环，编者也跟风采用输出倒逼输入的方式，试图恢复思考的习惯，跃出每次聊学习&lt;strong&gt;都只是推荐资料&lt;/strong&gt;，谈感悟都是&lt;strong&gt;只会说那讲的贼好&lt;/strong&gt;的怪圈，告别碎片化泡沫学习。墙裂推荐对本篇文章所谈内容感兴趣的朋友除了收藏转发之外找个数据库装个工具包亲自动手试试。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;傻瓜式学习模型&lt;/h2&gt;

&lt;p&gt;要足够简单才会流行起来！
将人类行为进行数量化标示，高级智能构建被简化成了搜索和拟合函数做选择的问题，一个深度学习系统能识别出图片中的各个物体因为它对这个检测框从给定的几十个甚至上千个类别中做了一个单项选择题然后标出一个 Label，吃瓜群众就会觉得这很神奇很棒，从某种程度上讲，这是一个魔术，能红极一时因为__IT WORKS!__，绝大多数研究者已经放弃了从高度抽象的逻辑推演构建人工智能这条路转而利用人工标数据来实现智能。。。&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;把大象装进冰箱需要几步？&lt;/h3&gt;
&lt;p&gt;在深度学习任务中，你只要：
选择网络结构-&amp;gt;确定学习目标-&amp;gt;进行学习。。。
&lt;em&gt;没了！！！&lt;/em&gt;
这让人逐渐理解生活大爆炸里 Sheldon 提到 Engineer 就会翻起的白眼，采用尽可能简单的模型，然后让一切湮没在海量的工程细节当中，每年招入大量的程序员加班加点不断走走停停，修修补补，整个 Computer Science 都未脱离各种细节的纠葛，暂时还称不上一门真正的科学。&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;我们的目标是？&lt;/h3&gt;
&lt;p&gt;没有蛀牙？？？不不不，实际系统目标多种多样，但无法用数学表示就无法代入公式，便不能转成代码让计算机去为我们工作。所以要有一个代价/目标函数来用数量化地表示我们的目标，将智能行为简化到一次单项选择的过程，网络要输出一个向量
$(x_1, x_2, x_3, …, x_n)$
而我们人工标出的数据以
${0, 0, …, 1, …, 0}$
的形式表示，后者 1 的位置代表正确的选择，其他位置都置 0，让输出向量尽可能逼近它，算一个 Mean Sequare Error 就好，比如向量(1,2)和(3,4)的 MSE 值是 ((1-3)^2 + (2-4)^2)/2，我们的目标就是让这个值尽可能地小&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;暴力求解！&lt;/h3&gt;
&lt;p&gt;我们眼中的照片，视频，耳机中播放的音乐，尽管惟妙惟肖，说到底都是一串数字信号，经过特征选择或者直接拿来都能抽成一个向量，变为我们系统的输入，向量中的每一个值都可能与我们最终的判定相关，到底用哪个数使用怎样的结构实在弄不清，干脆就让所有输入变量都与输出结果建立联系，用权值表示连接，管你相不相关，先一股脑连上，有多层抽象我就层层互连，把权值调来调去玩出花来就不信你效果不好。眼中浮现本科同学拿机器暴力枚举两天两夜搜索所有情况做数模的情景 Orz。本着 Engineering 的原则建立联系的时候直接采用加法，为了将计算放到一个可控的范围内，使用了一个形状像小肠名叫 Sigmoid 的函数，通过公式
$f(x) = \frac{1}{1+e^{-x}}$
将加和结果限制在(0, 1)区间
### 开荒？
暴力假设下有太多参数需要处理，即使是 1000 特征的输入到第一个维度为 500 的隐层的连接，算上 bias 就需要一个 1001*500 的矩阵存储，使用 double 类型存放权值大概是 4 MB 的空间需求，如果一个清晰度高一些的灰度图抽成向量直接输入，但这层就需要 100 MB+ 的存储空间，人多力量大参数多了效果好是没错。。。一般随机初始化各参数之后调参就成为了一个难题。&lt;/p&gt;

&lt;h2 id=&quot;section-5&quot;&gt;工匠精神&lt;/h2&gt;
&lt;p&gt;架子搭好了，忽悠结束了，接着就是实打实地磨刀，哦不，training 了，让我们步入工程细节当中。。。&lt;/p&gt;

&lt;h3 id=&quot;section-6&quot;&gt;偏导~&lt;/h3&gt;
&lt;p&gt;如果你七大姑的八大姨的二舅姥爷的小外甥和对象的年龄差三，那你和你对象的年龄差距大概是你和你七大姑的年龄差加上七大姑和二舅姥爷的年龄差加上二舅姥爷和小外甥的年龄差再算上那个三；神经网络看起来庞大复杂，但是使用基本结构连接组合获得的，将其看作一个多层函数嵌套的最终从目标函数输出误差值的整体看，直接使用偏导计算，在每一处算得特定参数对本层输出结果的导数乘上上层的偏导就能得到参数调整方向和幅度，或者说，一个 delta。看起来高达上的人工智能前沿领域，使用的跟 dota 里面手动探索地图产不多的方法，看走哪效果好就走哪里。&lt;/p&gt;

&lt;h3 id=&quot;mse-vs-cross-entropy&quot;&gt;MSE vs Cross Entropy&lt;/h3&gt;
&lt;p&gt;既然都是用导数，当然找个趁手的兵器很重要，MSE 太过平坦，大概是 A 吧。。从信息论那里借来 Cross Entropy 函数替换我们之前的目标函数加速训练，毕竟暴力方法太耗时，替换优化任何一个部分都能带来明显收益。&lt;/p&gt;

&lt;h3 id=&quot;sigmoid-vs-relu&quot;&gt;Sigmoid vs Relu&lt;/h3&gt;
&lt;p&gt;依然是慢的问题，sigmoid被替换成了一条可以简化为折线的 Relu；受到相关神经科学研究的启发，更多的激活函数得以应用，也让普通实现中 (0,1) 区间之外的数域获得得到利用，既然一条折线就能搞定。。似乎在讲将输入视为数值化的逻辑因子，0 代表不起效，正数值则代表着不同的作用权重，摆脱了 y = x 这样的激活函数效果等价于矩阵相乘依旧是矩阵表示的先行变换问题后，只用简单激活函数也能够发掘出多个参数矩阵的存储作用，承载更多信息并获得更快的训练速度。类似轮子、壳子、灯。。。加起来等于车子，每个参数表征一个特性，而特性是在实体间共享的，同时要包容所有特性分出车子、票子、房子的网络模型就会变得复杂，同时因为要一起做很多事情，网络的训练就变得繁难，跟解一团毛线一样，看起来简单，做起来却是另一个样子。
Relu 可以用式 relu(x)=log(1+exp(x)) 进行表示，或近似看作 y = max(0, x)，以及视作 maxout 的一种特殊情况。&lt;/p&gt;

&lt;h3 id=&quot;momentweight-decay-and-more&quot;&gt;Moment，Weight Decay and more…&lt;/h3&gt;
&lt;p&gt;更进一步来讲，还有分批训练等方法。在利用导数通过梯度下降降低损失值的时候，并不能保证找到全局最优解，就效仿物理概念加上一个动量让训练不要轻易停(go)止(dai)，多跑跑总会有更大几率得到更好训练效果的（默默想到动量守恒什么的。。。）。为了防止在训练集想太多，还通过减枝、early stop 和权值衰减让长期得不到激活的权值随训练递减逐渐拉近训练集和验证集上的效果差距，以争取更好的测试结果。&lt;/p&gt;

&lt;h3 id=&quot;section-7&quot;&gt;就决定是你了，皮卡丘！&lt;/h3&gt;
&lt;p&gt;针对不同任务网络有很多变形，类似小智针对不同战斗要使用不同的小精灵比赛一样。
在视觉任务当中，基础特征具有良好的空间布局，加上人自身看东西有从小处见整体的能力(gaze)，采用多个卷积核扫描整张图片经过降采样(max pooling之类)逐层进行特征抽象，最后抽成特征向量会比直接输入一个超长向量直截了当的多，通常大家用 CNN 作为这种方法的简称。
另外的，对于有时序信息影响的任务，RNN 以及更复杂的 LSTM 玩得转的话可以处理这些问题。
当然，方法的具体实现涉及并行计算、超大数据量的处理等多方面的内容，不是三下两下能解决的，最好采用分数计算方法，浮点数在一些情况下并不够用。
像小时候的四驱车一样，大家都知道要马达，要轮胎，但给你一桶油一个铁块一般是早不出来的，大家的四驱车基本靠买。。。
号称搞深度学习的，大部分是通过使用工具包像搭积木一样拼接网络站在前人工作基础之上做事情。&lt;/p&gt;

&lt;h2 id=&quot;section-8&quot;&gt;未来？&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;集合多任务构造 Active Memory?&lt;/li&gt;
  &lt;li&gt;继续加深网络结构？&lt;/li&gt;
  &lt;li&gt;more an more
类似教科书里写过做风车的牛顿，我们找到了一个好玩的玩具，用处也多，却并不能清楚回答 __why it works ? 的问题；希望能扒出像三定律，麦克斯韦的方程组，爱因斯坦的相对论那样简介而美的东西。。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;不过也说不定呢，人本来就是嬗变的，用计算机模拟人脑活动是一次自省的过程，啥都试一试如同神农尝百草，高兴之余也要继续 meditation 才能悟道&lt;/p&gt;
</description>
        <pubDate>Wed, 09 Nov 2016 11:17:00 +0000</pubDate>
        <link>http://talkwithme.cn//2016/11/09/1DayDeepLearning/</link>
        <guid isPermaLink="true">http://talkwithme.cn//2016/11/09/1DayDeepLearning/</guid>
        
        
      </item>
    
      <item>
        <title>深度学习-工具之痛</title>
        <description>&lt;h2 id=&quot;section&quot;&gt;前言&lt;/h2&gt;

&lt;p&gt;部分程序员掌握修电脑装系统的技能通常是由于手贱。。。&lt;/p&gt;

&lt;p&gt;编者笔记本和 Ubuntu 启动盘死磕上瘾一次启动24小时都进不去界面之后只能转战老旧的台式机了。。。顺手想装装系统捞几个工具库来用一搞就是一天～&lt;/p&gt;

&lt;p&gt;公号最近实在没别的可说的，就赶时髦来聊聊深度学习，主要吐槽工具包。&lt;/p&gt;

&lt;p&gt;当初像我这么肤浅的人竟误入了深度学习的坑，主要是想着这样的东西可以反过来帮助我们理解人脑为祖国的教育事业做贡献；naive，这种十八弯一样的思路把八杆子打不着的东西凑一起也是闹。&lt;/p&gt;

&lt;p&gt;有关神(shen)经(du)网(xue)络(xi)的英文资料一抓一大把了，可不吐不快，不写出来实在不知道自己知道点啥。&lt;/p&gt;

&lt;p&gt;程序运行的过程如同一场演出，观众与导演的角色截然不同；用户是前排看戏的，各种数据结构工具库加上杂七杂八的硬件是场上演出的，写程序的家伙们则是后台忙里忙外的，稍不留神就一个趔趄摔倒在地被一堆电缆缠的动弹不得，被 bug 咬地满头包。。。这种时候找个靠谱的工具包十分必要，如同普通青年小时候玩四驱车得把原件买来才行，空手造一个顶多捏个纸的。&lt;/p&gt;

&lt;p&gt;关于深度学习到底是个啥推荐各位阅读—__李宏毅：一天搞懂深度学习__，二百多页的 PPT 能让人看到这项技术的大概轮廓；由于坑多，相关主题在部分科研学者圈子里还会继续火下去。作为打工仔，编者最关心的是工具包的问题。&lt;/p&gt;

&lt;p&gt;别家的网络和工具拿来用如同套公式一样往 paper 里塞，胃容量小的我实在受不了这样填鸭，在去年的暑假尝试着用 C 写一套自己的工具自用，未果。。。一周后卡在 BP 部分上丢在 github 上作未完待续状，这种时候只好抱抱大腿先。&lt;/p&gt;

&lt;p&gt;一条咸鱼在各种工具包中翻滚过，到头来对它们的了解大概只有这么浅，烛火微光，防止朋友踩坑。。。以下工具包均可在网络上开放获取，特别鸣谢著名同性交友社区 Github 的代码托管支持。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Pybrain -Jürgen Schmidhuber 的学生在距今十年前就开始的项目，速度不(hen)快(man)，但里面的实现简捷漂亮，可以初学使用，并在小规模数据下进行网络验证与快速实验。&lt;/li&gt;
  &lt;li&gt;FANN - 当前年龄在十岁以上诞生自丹麦的神经网络工具包，使用 C 语言实现，可以方便移植，网络上可搜索到编译并将其嵌入到 IOS APP 的博文。&lt;/li&gt;
  &lt;li&gt;Matconvnet - vlfeat 工程组为广大 Matlab 死忠准备的 CNN 工具包，方便简单见效快。&lt;/li&gt;
  &lt;li&gt;Kaldi - 语音相关领域研究者青睐的专门工具包&lt;/li&gt;
  &lt;li&gt;CNTK - 微软深度学习框架，最近改了名字。&lt;/li&gt;
  &lt;li&gt;Theano - 蒙特利尔出产的使用广泛而历史也比较久的工具&lt;/li&gt;
  &lt;li&gt;Torch - 产自纽约大学，使用轻量化的 Lua 力求最大的灵活性，贴着 Facebook 的标签&lt;/li&gt;
  &lt;li&gt;Caffe - 某乎网红论文搞定剩下俩月没事干写出来的工具包，对于大数据量需要使用 GPU 加速训练深层网络的情况尤其合适，2014 年来广受欢迎&lt;/li&gt;
  &lt;li&gt;cuRRent - 简单易用语音相关神经网络工具包&lt;/li&gt;
  &lt;li&gt;Tensorflow - 黄金工程团队谷歌开源的内部机器学习系统&lt;/li&gt;
  &lt;li&gt;Keras - 套在 Theano 和 Tensorflow 外层上的很好用的壳&lt;/li&gt;
  &lt;li&gt;mxnet - 神秘组织 dmlc 产物，支持语言非常全&lt;/li&gt;
  &lt;li&gt;darknet - Little Pony 爱好者 Joseph 凭着本科时撸 ACM 的功力写的工具包，基本没什么工具依赖，相对那些大号工具包代码量小跑的很快，用起来只要一个可执行文件就好。&lt;/li&gt;
  &lt;li&gt;DIGITS - 核弹厂给 Caffe 加的一层壳&lt;/li&gt;
  &lt;li&gt;opencv - 今年的 Google Summer of Code 活动学生们决定为开发中的 opencv 版本继续完善神经网络相关的部分，之前的版本只有感知机可用&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;讲真，被滥用的深度学习方法看起来简直是核弹厂老黄卖显卡、公司围攻傲娇研究团体、小年轻在老学究圈子里搏出位的必备出装。只想说，显卡是 AMD 或者 N 卡计算能力低于 2.0 的，机器固件和 Ubuntu 有仇的，只要是工具包都喜欢尝尝鲜用最新版的，入坑都要三思而后行。&lt;/p&gt;

&lt;h2 id=&quot;xor-in-pybrain&quot;&gt;XOR in Pybrain&lt;/h2&gt;
&lt;p&gt;开始接触一个工具总要有个 Hello World 一样的东西，当年感知机被指出的致命缺点就是无法学到 xor。&lt;/p&gt;

&lt;p&gt;要逼近亦或函数，在神经网络里加上隐层即可。&lt;/p&gt;

&lt;p&gt;豪杰解霸的作者当年招进去的一批员工发展最好的是个入职只会 C 语言的，花里胡哨的技术太多，太该紧跟潮流反而学不到真东西，或者说练不到内功。。用牺牲速度换取易用性的 Pybrain，我们可以快速构建一个简单网络并进行实验，参照官方文档对应代码如下。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pybrain.tools.shortcuts&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;buildNetwork&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pybrain.structure&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SoftmaxLayer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TanhLayer&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pybrain.datasets&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SupervisedDataSet&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pybrain.supervised.trainers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BackpropTrainer&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;buildNetwork&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hiddenclass&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TanhLayer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outclass&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SoftmaxLayer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SupervisedDataSet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;addSample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;addSample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;addSample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;addSample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;trainer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BackpropTrainer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;trainer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trainUntilConvergence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;activiate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;要具体查看网络结构以及数据内容，可以使用库自带的接口&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;in&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;hidden0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;out&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;activate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;input&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;target&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里我们讲 XOR 作为一个简单而具有代表性的思维模型，用神经网络进行拟合，把离散的问题归入连续函数模型当中，利用给出样本进行逼近，试了试这条路是不是走的通。微信发代码技能 get!下节，我们从一个填空题的角度来看这些代码处理的对象是个什么鬼。。&lt;/p&gt;
</description>
        <pubDate>Wed, 02 Nov 2016 11:17:00 +0000</pubDate>
        <link>http://talkwithme.cn//2016/11/02/DLPain/</link>
        <guid isPermaLink="true">http://talkwithme.cn//2016/11/02/DLPain/</guid>
        
        
      </item>
    
      <item>
        <title>Blog-Pyimagesearch</title>
        <description>&lt;h1 id=&quot;section&quot;&gt;我在构建图片搜索引擎时最喜欢的九个库&lt;/h1&gt;
&lt;blockquote&gt;
  &lt;p&gt;by Adrian Rosebrock on January 12, 2014 in Libraries&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;To be continued, 看博主本人后期玩什么吧&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        <pubDate>Wed, 27 Jul 2016 00:15:00 +0000</pubDate>
        <link>http://talkwithme.cn//2016/07/27/Blog-Pyimagesearch/</link>
        <guid isPermaLink="true">http://talkwithme.cn//2016/07/27/Blog-Pyimagesearch/</guid>
        
        
      </item>
    
      <item>
        <title>Programming Languages</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;第一次注册课程，发现要用emacs什么的，弃了，年少无知，有时候感到越困难，隐藏的收获就越大。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;section&quot;&gt;笔记&lt;/h2&gt;

&lt;h4 id=&quot;week-1&quot;&gt;Week 1&lt;/h4&gt;

&lt;h6 id=&quot;introduction-and-course-wide-information&quot;&gt;Introduction and Course-Wide Information&lt;/h6&gt;
&lt;ul&gt;
  &lt;li&gt;Start here-这是最具挑战性也是让人收获最多的MOOC之一&lt;/li&gt;
  &lt;li&gt;nt-作业只能交一次，重点在揭示编程语言背后的ideas，难度更大但也更正规，老师写文档很棒。
之前看instruction然后做填空的作业方式会让事情变得无聊，试错然后看错误是不是如自己预期那样发生，玩起来才有意思。&lt;/li&gt;
  &lt;li&gt;nt-Dan这么详细的自我介绍和课程介绍是要和同学们交朋友的节奏啊。。。&lt;/li&gt;
  &lt;li&gt;nt-Simplicity is a virtue，让课程讲者来告诉我们如何上这门课，Karate Kids，有意思的电影推荐。
在之前对即将学到的见到的东西没有预估，经常“一言不合”，课上的没有愉悦感，也许在这门课里面应该动动脑子和课程交个朋友。&lt;/li&gt;
  &lt;li&gt;nt-Ops，别人家大二大三的课程，落后好大一截了，需要我们了解varibles, conditionals, loops, arrays, recursion等概念，dynamic-dispatch不资到，好像是用类继承的。
少有的见到老师直播编程的机会，写了个自带求树上所有元素和的二叉树。&lt;/li&gt;
  &lt;li&gt;nt-视频卡成狗了，底下字幕可以直接看真心赞，很多时候并不一定需要视频，老师顺带吐槽分成三块挺麻烦的而且不应该这样做。。整个大概要100到200小时，do not lose momentum。&lt;/li&gt;
  &lt;li&gt;nt-看视频不是必须的，但能够帮助highlights key points，老师对MOOC有读到见解，尽力复现在华大的课程，少与定死的auto-grader打交道，通过peer-review与同学打交道&lt;/li&gt;
  &lt;li&gt;nt-Jargons show，到Part B会着手实现解释器来构建语言，Part C重点在面向对象，leave this course with a lot of food for thought and a lot of new perspectives，课程长期视作负担，学习看作居中是个坏姿势&lt;/li&gt;
  &lt;li&gt;nt-课程的讲稿和讨论区&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;software-installation-and-homework-0&quot;&gt;Software Installation and Homework 0&lt;/h6&gt;
&lt;ul&gt;
  &lt;li&gt;Why Emacs?-In hindsight老Emacs能为我们做什么？便于写实验指导书。。。老师看起来完全不是在安利emacs&lt;/li&gt;
  &lt;li&gt;Part A Software Installation and Use: SML and Emacs-Emacs用起来真是复古，名词都不一样。。。好多细节，被四个人合作写得清清楚楚。之后要再来光顾，还不知道emacs是怎么找到并调用sml的&lt;/li&gt;
  &lt;li&gt;nt-视频讲解软件安装方法，并没有找到pdf文档下载地方&lt;/li&gt;
  &lt;li&gt;nt-交了一次“假”作业&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;week-2&quot;&gt;Week 2&lt;/h4&gt;

&lt;h6 id=&quot;section-wide-items&quot;&gt;Section-Wide Items&lt;/h6&gt;
&lt;ul&gt;
  &lt;li&gt;Section 1 Welcome Message-好多新词，variables, numbers, conditionals, scope, shadowing, function, pairs, lists, let expression, local binding, nested functions, options, booleans&lt;/li&gt;
  &lt;li&gt;nt-&lt;/li&gt;
  &lt;li&gt;nt-&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;video-lectures&quot;&gt;Video Lectures&lt;/h6&gt;
&lt;ul&gt;
  &lt;li&gt;​&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Mon, 25 Jul 2016 11:17:00 +0000</pubDate>
        <link>http://talkwithme.cn//2016/07/25/MOOCBook-ProgrammingLanguages/</link>
        <guid isPermaLink="true">http://talkwithme.cn//2016/07/25/MOOCBook-ProgrammingLanguages/</guid>
        
        
      </item>
    
      <item>
        <title>MOOCBook-Coursera-Robotics-Aerial Robotics</title>
        <description>&lt;h1 id=&quot;why-this-course&quot;&gt;Why this course?&lt;/h1&gt;
&lt;p&gt;Last year, Peter Corke opened my eye to fascinating robotics world(by taking his course on &lt;a href=&quot;mooc.qut.edu.au&quot;&gt;QUT MOOC&lt;/a&gt;), but the course material no more availible after the course closed.
Robotics-Aerial Robotics is part of the series provided by Penn on Coursera and I paid for it. Have to finish the course anyway…&lt;/p&gt;

&lt;p&gt;槽点颇多的新开课程。。。视频和作业不大能对上号什么的~~追赶时尚潮流总要付出点代价的，ps，这。。。不算是没有任何基础能应付自如的课&lt;/p&gt;

&lt;h1 id=&quot;video-lecture-notes&quot;&gt;Video Lecture Notes&lt;/h1&gt;

&lt;h6 id=&quot;week-1&quot;&gt;Week 1&lt;/h6&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Introduction-Prof Kostas Daniilidis and Prof Jianbo Shi(zi mu you du, ming zi dou da cuo le) are going to teach us how to extract information through images and videos.
Information including position, trajectory, distance to the points in the scene of the camera. Syllabus: W1 Geometry of Projection, W2 Augmented Reality, W3 Visual Metrology, W3+4 Orient ourselves in 3D through 2D information.
Interesting, Prof Shi illustrated two ways to orient oneself in 3D space(by inferring what was know or point correspondance).
Boundle adjustment for 3D reconstruction with more images. The course is challenging while taking picture seems an easy job…&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Camera modeling-What is a camera, an old question from high school physics class, gannets as example of distance measuring(paper about this animal by David N. Lee: Plummeting gannets: a paradigm of ecological optics).
Kostas showed his camera(image/CCD chip and lens) collection, he mentioned the property of the thin lens.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{1}{f} = \frac{1}{a} + \frac{1}{b}&lt;/script&gt;

&lt;p&gt;focal length, object distance, image plane distance. Size ratio:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{Y}{a} = \frac{y}{b}&lt;/script&gt;

&lt;p&gt;Multiple points on a line projects to the same point on the image plane.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Single view geometry-I thought we are looking down at first Prof Shi…Try to infer the geometry of the scene as well as how the camera man is looking into the scene.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;questions&quot;&gt;Questions&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Why most precise image got when requirement of 
&lt;script type=&quot;math/tex&quot;&gt;\frac{1}{f} = \frac{1}{a} + \frac{1}{b}&lt;/script&gt;
met.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sat, 23 Jul 2016 05:30:00 +0000</pubDate>
        <link>http://talkwithme.cn//2016/07/23/MOOCBook-Coursera-Robotics-Aerial-Robotics/</link>
        <guid isPermaLink="true">http://talkwithme.cn//2016/07/23/MOOCBook-Coursera-Robotics-Aerial-Robotics/</guid>
        
        
      </item>
    
      <item>
        <title>Moocbook Msra Bigdata</title>
        <description>&lt;p&gt;﻿—
layout: post
comments: true
title:  “MOOCBook-MSRA-BIGDATA”
excerpt: “高大上的MSRA发布了高大上的大数据系列讲座。。。平心而论，内容足够前言但课程质量并没有很多亮眼的地方，跟着巨硬研究院的招牌听说还能申请实习岗位也就入坑了”
date:   2016-07-15 03:27:00
—&lt;/p&gt;

&lt;h1 id=&quot;video-lecture-notes&quot;&gt;Video Lecture Notes&lt;/h1&gt;

&lt;h6 id=&quot;week1-&quot;&gt;Week1-什么是大数据&lt;/h6&gt;
&lt;p&gt;这段就当记Dr Hong语录了，数据暴涨，大堤决口，能在当今时代生存的企业必须是数据海洋的弄潮儿。
BIG DATA MEANS BIG MONEY for companies like 巨硬。
世界变化越发迅速，越来越多的生意如同民航领域一样必须迅速做出决策适应市场变化，这种变化反映到消费者那端，是如同机票售价一样不断变化的价格，反映到公司内部，则是大数据产业的兴起。
这玩意靠谱么?麦肯锡在几年前炒起来的概念带着一堆云里雾里的新名词，其中干货到底几斤几两不免让人生疑。
欲知后事如何，只能继续上课！&lt;/p&gt;

&lt;h6 id=&quot;week1--1&quot;&gt;Week1-为什么大数据是当前热点&lt;/h6&gt;
&lt;p&gt;这十八分钟被洪先生的连珠炮般的概念糊了一脸，高中时候计算器就已经代表着电脑的高级形态了，
到了台大整个学校一起用一台Univex，当时还有数据录入员这样的工作。
随着Natural Progress of Digitalization of Everything的趋势，数据的获取和存储成本逐渐降低趋向于0，
从最初的文档到后来的音乐视频再到互联网社交网物联网，越来越多的东西被数位化&lt;/p&gt;

&lt;p&gt;很佩服研究者的远见，在计算能力还不足的时候不全都跑去刷计算速度而投身更前沿的工作。
过去使用模型借由数学的力量(Unreasonable effectiveness of mathematics)所做的事情里数据最多用来打下手，但人类天生是一种Learning by Example的复杂动物，
1700页厚的语法书也难以应对自然语言处理所需的所有情况，我们需要用数据来直接解决问题，借着数据量的增加和计算能力的增强，
过去想做而做不到的事情一步步被后人实现。&lt;/p&gt;

&lt;p&gt;其它比如五道口受文艺复兴公司捐建的楼，MyLifeBits项目说人的一生用1T就装得下，做语音的数据量每提升一倍错误率下降为原来的二分之一，每炒掉一个老派研究者错误率下降百分之十这些梗有兴趣的朋友回头可以回视频慢慢看。
如何有效检索与利用大量数据是可以继续开荒的研究领域，不然总不能在MyLifeBits项目里坐看五年视频找回人生中一个片段吧。另外，官方资料有限的时候怎么从油管等地方扒料也是技术活(combine data)，破除存储本身带来的地坑式的数据牢笼。&lt;/p&gt;

&lt;p&gt;最后我们手上可用的数据数起来有这么些：
+ 企业ERP/CRM数据
+ 各类交易数据
+ 用户数据
+ 社交数据
+ 传感数据
+ 系统日志文件
+ 公共数据(网络数据)&lt;/p&gt;
</description>
        <pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate>
        <link>http://talkwithme.cn//2016/07/15/MOOCBook-MSRA-BIGDATA/</link>
        <guid isPermaLink="true">http://talkwithme.cn//2016/07/15/MOOCBook-MSRA-BIGDATA/</guid>
        
        
      </item>
    
      <item>
        <title>MOOCBook-opencourse-ml-andrewng</title>
        <description>&lt;h1 id=&quot;why-this-course&quot;&gt;Why this course?&lt;/h1&gt;
&lt;p&gt;来考古的，课程里面还在用Windows98。。。Andrew Ng提供的机器学习课程的原始出处，课程最大特点是平易近人。&lt;/p&gt;

&lt;h1 id=&quot;tao-lu&quot;&gt;Tao Lu&lt;/h1&gt;
&lt;p&gt;老师开头总要讲讲历史，说明自己知识是哪里来的，展示些好玩的东西，引发学生们的兴趣，这些都是套路，试着复述课程中的关键内容，要记得课程的重点是那些让人不明白的地方。&lt;/p&gt;

&lt;h1 id=&quot;video-lecture-notes&quot;&gt;Video Lecture Notes&lt;/h1&gt;

&lt;h6 id=&quot;alphabet&quot;&gt;Alphabet&lt;/h6&gt;
&lt;ul&gt;
  &lt;li&gt;Regression&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;lecture-1&quot;&gt;Lecture 1&lt;/h6&gt;
&lt;ul&gt;
  &lt;li&gt;显然，机器学习作为一个研究领域部分目的在于扩展计算机的处理能力，这是一个前沿/交叉学科，或者换句话说，做的是杂活，Andrew鼓励将课程的Project定为在自己的当前研究方向上使用机器学习算法解决特定任务。
第一节课，为了显得cool一些，举了很多例子，用Dan收集的房价信息作Regression问题的示例，肿瘤细胞检测作classification问题的示例，预言ML在医疗领域大有用处，也让人想到Eric Xing和匹兹堡医院的合作。
行胜于言，Authur Samuel在1959年真切地拿出来一个通过训练获得的下跳棋的程序是在ML领域开荒的“壮举”，更formal的定义则是Tom Mitchell的E, P, T形式。
提到了高维度的问题(如果不止通过size和)，这也是很多实际应用中要解决的核心问题。
在非监督学习部分给出很吸引人的例子，通过图片重建世界支持3D Navigation，unsupervised learning在其中起到预处理作用。
鸡尾酒会的例子真是用烂了，里面的ICA算法用一行代码表示起来就是：
&lt;code class=&quot;highlighter-rouge&quot;&gt;Matlab
[W,s,v] = svd((repmat(sum(x.*x,1),size(x,1),1).*x)*x&#39;);
&lt;/code&gt;
老实说，对于上面代码具体做了什么真的不太懂。
至于Reinforcement Learning，给大家看了小飞机和学生做的不同种类的机器人。课程暂不涉及RL。
课程数学基础要求有基本的统计知识，了解方差，期望这些概念，具备基本线性代数知识，最好知道特征向量。
本课中的消化大概就是Andrew在另一个学校工作的朋友从前学ML的学生回来show Matlab码来的BIG House照片和数数鸡尾酒会了。。。&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 08 Jul 2016 04:30:00 +0000</pubDate>
        <link>http://talkwithme.cn//2016/07/08/MOOCBook-opencourse-ml-andrewng/</link>
        <guid isPermaLink="true">http://talkwithme.cn//2016/07/08/MOOCBook-opencourse-ml-andrewng/</guid>
        
        
      </item>
    
      <item>
        <title>MOOCBook-Coursera-Robotics-Perception</title>
        <description>&lt;h1 id=&quot;why-this-course&quot;&gt;Why this course?&lt;/h1&gt;
&lt;p&gt;Last year, Peter Corke opened my eye to fascinating robotics world(by taking his course on &lt;a href=&quot;mooc.qut.edu.au&quot;&gt;QUT MOOC&lt;/a&gt;), but the course material no more availible after the course closed.
Robotics-Perception is part of the series provided by Penn on Coursera and I paid for it. Have to finish the course anyway…&lt;/p&gt;

&lt;h1 id=&quot;video-lecture-notes&quot;&gt;Video Lecture Notes&lt;/h1&gt;

&lt;h6 id=&quot;alphabet&quot;&gt;Alphabet&lt;/h6&gt;
&lt;ul&gt;
  &lt;li&gt;Vanishing point, Horizon, Optical center, Prependicular, peephole&lt;/li&gt;
  &lt;li&gt;panoramic, magnifying glass, focusing, plummet&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;week-1&quot;&gt;Week 1&lt;/h6&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Introduction-Prof Kostas Daniilidis and Prof Jianbo Shi(zi mu you du, ming zi dou da cuo le) are going to teach us how to extract information through images and videos.
Information including position, trajectory, distance to the points in the scene of the camera. Syllabus: W1 Geometry of Projection, W2 Augmented Reality, W3 Visual Metrology, W3+4 Orient ourselves in 3D through 2D information.
Interesting, Prof Shi illustrated two ways to orient oneself in 3D space(by inferring what was know or point correspondance).
Boundle adjustment for 3D reconstruction with more images. The course is challenging while taking picture seems an easy job…&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Camera modeling-What is a camera, an old question from high school physics class, gannets as example of distance measuring(paper about this animal by David N. Lee: Plummeting gannets: a paradigm of ecological optics).
Kostas showed his camera(image/CCD chip and lens) collection, he mentioned the property of the thin lens.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{1}{f} = \frac{1}{a} + \frac{1}{b}&lt;/script&gt;

&lt;p&gt;focal length, object distance, image plane distance. Size ratio:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{Y}{a} = \frac{y}{b}&lt;/script&gt;

&lt;p&gt;Multiple points on a line projects to the same point on the image plane.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Single view geometry-I thought we are looking down at first Prof Shi…Try to infer the geometry of the scene as well as how the camera man is looking into the scene.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;questions&quot;&gt;Questions&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Why most precise image got when requirement of 
&lt;script type=&quot;math/tex&quot;&gt;\frac{1}{f} = \frac{1}{a} + \frac{1}{b}&lt;/script&gt;
met.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 07 Jul 2016 05:30:00 +0000</pubDate>
        <link>http://talkwithme.cn//2016/07/07/MOOCBook-Coursera-Robotics-Perception/</link>
        <guid isPermaLink="true">http://talkwithme.cn//2016/07/07/MOOCBook-Coursera-Robotics-Perception/</guid>
        
        
      </item>
    
      <item>
        <title>Robotics Vision</title>
        <description>&lt;h1 id=&quot;robotic-vision&quot;&gt;Robotic Vision&lt;/h1&gt;

&lt;h2 id=&quot;section&quot;&gt;课程体验&lt;/h2&gt;
</description>
        <pubDate>Sat, 02 Jul 2016 11:17:00 +0000</pubDate>
        <link>http://talkwithme.cn//2016/07/02/MOOCBook-Robotics-Vision(QUT,-Peter-Corke)/</link>
        <guid isPermaLink="true">http://talkwithme.cn//2016/07/02/MOOCBook-Robotics-Vision(QUT,-Peter-Corke)/</guid>
        
        
      </item>
    
      <item>
        <title>Introduction to Robotics</title>
        <description>&lt;h1 id=&quot;introduction-to-robotics&quot;&gt;Introduction to Robotics&lt;/h1&gt;

&lt;h2 id=&quot;section&quot;&gt;课程体验&lt;/h2&gt;
&lt;p&gt;机器人是最好玩最好玩的东西了，可大可小，可硬可软，咳咳，宾大的课程不太亲民，还是回来找去年国庆无意发现的Peter Corke提供的好玩课程来长见识，忍着网速蹭着油管下载视频跪着也想上的课。&lt;/p&gt;
</description>
        <pubDate>Sat, 02 Jul 2016 11:13:00 +0000</pubDate>
        <link>http://talkwithme.cn//2016/07/02/MOOCBook-Intro2Robotics(QUT,-Peter-Corke)/</link>
        <guid isPermaLink="true">http://talkwithme.cn//2016/07/02/MOOCBook-Intro2Robotics(QUT,-Peter-Corke)/</guid>
        
        
      </item>
    
  </channel>
</rss>
